#' ---
#' title: "Lista 1 - Inteligencia computacional"
#' author: "Bruno Tebaldi Q Barbosa"
#' date: "11/08/2021"
#' output: html_document
#' ---


#' ## Questão 1
#' 


#' **Attributes for both student-mat.csv (Math course) and student-por.csv (Portuguese language course) datasets:**
#' 
#' - 1 school - student's school (binary: "GP" - Gabriel Pereira or "MS" - Mousinho da Silveira)
#' - 2 sex - student's sex (binary: "F" - female or "M" - male)
#' - 3 age - student's age (numeric: from 15 to 22)
#' - 4 address - student's home address type (binary: "U" - urban or "R" - rural)
#' - 5 famsize - family size (binary: "LE3" - less or equal to 3 or "GT3" - greater than 3)
#' - 6 Pstatus - parent's cohabitation status (binary: "T" - living together or "A" - apart)
#' - 7 Medu - mother's education (numeric: 0 - none,  1 - primary education (4th grade), 2 – 5th to 9th grade, 3 – secondary education or 4 – higher education)
#' - 8 Fedu - father's education (numeric: 0 - none,  1 - primary education (4th grade), 2 – 5th to 9th grade, 3 – secondary education or 4 – higher education)
#' - 9 Mjob - mother's job (nominal: "teacher", "health" care related, civil "services" (e.g. administrative or police), "at_home" or "other")
#' - 10 Fjob - father's job (nominal: "teacher", "health" care related, civil "services" (e.g. administrative or police), "at_home" or "other")
#' - 11 reason - reason to choose this school (nominal: close to "home", school "reputation", "course" preference or "other")
#' - 12 guardian - student's guardian (nominal: "mother", "father" or "other")
#' - 13 traveltime - home to school travel time (numeric: 1 - <15 min., 2 - 15 to 30 min., 3 - 30 min. to 1 hour, or 4 - >1 hour)
#' - 14 studytime - weekly study time (numeric: 1 - <2 hours, 2 - 2 to 5 hours, 3 - 5 to 10 hours, or 4 - >10 hours)
#' - 15 failures - number of past class failures (numeric: n if 1<=n<3, else 4)
#' - 16 schoolsup - extra educational support (binary: yes or no)
#' - 17 famsup - family educational support (binary: yes or no)
#' - 18 paid - extra paid classes within the course subject (Math or Portuguese) (binary: yes or no)
#' - 19 activities - extra-curricular activities (binary: yes or no)
#' - 20 nursery - attended nursery school (binary: yes or no)
#' - 21 higher - wants to take higher education (binary: yes or no)
#' - 22 internet - Internet access at home (binary: yes or no)
#' - 23 romantic - with a romantic relationship (binary: yes or no)
#' - 24 famrel - quality of family relationships (numeric: from 1 - very bad to 5 - excellent)
#' - 25 freetime - free time after school (numeric: from 1 - very low to 5 - very high)
#' - 26 goout - going out with friends (numeric: from 1 - very low to 5 - very high)
#' - 27 Dalc - workday alcohol consumption (numeric: from 1 - very low to 5 - very high)
#' - 28 Walc - weekend alcohol consumption (numeric: from 1 - very low to 5 - very high)
#' - 29 health - current health status (numeric: from 1 - very bad to 5 - very good)
#' - 30 absences - number of school absences (numeric: from 0 to 93)
#'
#' These grades are related with the course subject, Math or Portuguese:
#' 
#' - 31 G1 - first period grade (numeric: from 0 to 20)
#' - 31 G2 - second period grade (numeric: from 0 to 20)
#' - 32 G3 - final grade (numeric: from 0 to 20, output target)
#' 
#' Additional note: there are several (382) students that belong to both datasets . 
#' 
#' - These students can be identified by searching for identical attributes
#' - that characterize each student, as shown in the annexed R file.


# Setup -------------------------------------------------------------------

rm(list = ls())

library(readr)
library(dplyr)
library(glmnet)


#' ### Item a)
#' Carregue os dados disponíveis no e-class ("student-por.csv").

# Data load ---------------------------------------------------------------
student_mat <- read_delim(here::here("AX - Lasso/Database/student-por.csv"), 
                          delim = ";",
                          escape_double = FALSE,
                          trim_ws = TRUE)



#' ### Item b)
#' Determine as estatísticas descritivas do banco de dados.

# Estatistica descritivas -------------------------------------------------
str(student_mat)
summary(student_mat)


#' ### Item c)
#' Exclua da analise de dados as colunas trabalho da mãe (Mjob),
#' trabalho do pai (Fjob), razão de escolha da escola (reason), guardião do
#' aluno (guardian), Nota da segunda e terceira avaliação (G2 e G3).
#' 
#' ### Item d)
#' Transforme as demais variáveis categorias em variáveis numéricas. Esse
#' procedimento é necessário pois tanto *Ridge Regression* quanto
#' *Lasso Regression* trabalham com variáveis numéricas.


# Padronizacao de variaveis -----------------------------------------------

for (col in colnames(student_mat)) {

  if(!is.numeric(student_mat[[col]])) {

    aux <- factor(student_mat[[col]])
    
    if(length(levels(aux)) != 2){
        # cat(col, " has more than two levels\n" )
      cat("Dropping", col, "\n" )
      student_mat[col] = NULL
    }
    else{
      student_mat[col] <- as.numeric(aux) -1
      
      cat(sprintf("%s = 0\t%s = 1\n", levels(aux)[1], levels(aux)[2]))
    }
  }
}

student_mat <- student_mat %>% select(-G2,-G3) 




#' ### Item e)
#' A regressão assume que os preditores são padronizados e a
#' variável dependente é centralizada. Vamos prever G1, Sendo assim aplique as
#' devidas transformações.

# Padronizacao das variaveis ----------------------------------------------

y <- student_mat %>% select(G1) %>% scale(center = TRUE, scale = FALSE) %>% as.matrix()
X <- student_mat %>% select(-G1) %>% scale() %>% as.matrix()




#' ### Item f)
#' Utilizando um modelo de *Ridge Regression*, determine os itens abaixo:
#'
#' - Utilize 10 *folds* em um processo de cross-validation para determinar o melhor valor de lambda.($\lambda \in [10^{-3}, 10^4]$).
#' - Determine os coeficientes do modelo, para o melhor lambda escolhido no item anterior. Obter também a soma de resíduos quadrados e $R^2$
#' - Avalie como os coeficientes se comportam com a variação do lambda.


# Ridge Regression - cross-validation -------------------------------------
lambdas_to_try <- 10^seq(-3, 4, length.out = 100)

ridge_cv <- cv.glmnet(X, y,
                      alpha = 0,
                      lambda = lambdas_to_try,
                      standardize = FALSE,
                      nfolds = 10)

# Plot cross-validation results
plot(ridge_cv)

# Best cross-validated lambda
lambda_cv <- ridge_cv$lambda.min

# Ridge Regression - coeficientes, SSR e R2 -------------------------------

model <- glmnet(X, y, alpha = 0, lambda = lambda_cv, standardize = FALSE)

# Coeficientes do modelo
coef(model)

# Fitted values
y_hat <- predict(model, X)
SSR <- t(y - y_hat) %*% (y - y_hat)
rsq_ridge <- cor(y, y_hat)^2

cat(sprintf("SSR: %5.3f\n R2: %5.3f", SSR, rsq_ridge))

# Ridge Regression - coeficientes vs lambda -------------------------------

res <- glmnet(X, y, alpha = 0, lambda = lambdas_to_try, standardize = FALSE)
plot(res, xvar = "lambda")




#' ### Item g)
#' Utilizando um modelo de *Lasso Regression*, determine os itens abaixo:
#' - Utilize 10 *folds* em um processo de cross-validation para determinar o melhor valor de lamba.($\lambda \in [10^{-3}, 10^4]$).
#' - Determine os coeficientes do modelo, para o melhor lambda escolhido no item anterior. Obter também a soma de resíduos quadrados e $R^2$
#' - Avalie como os coeficientes se comportam com a variação do lambda.

# Lasso Regression - cross-validation -------------------------------------

lambdas_to_try <- 10^seq(-3, 4, length.out = 100)

ridge_cv <- cv.glmnet(X, y,
                      alpha = 1,
                      lambda = lambdas_to_try,
                      standardize = FALSE,
                      nfolds = 10)

# Plot cross-validation results
plot(ridge_cv)

# Best cross-validated lambda
lambda_cv <- ridge_cv$lambda.min


# Lasso Regression - coeficientes, SSR e R2 -------------------------------

model <- glmnet(X, y, alpha = 1, lambda = 1, standardize = FALSE)

# Coeficientes do modelo
coef(model)

# Fitted values
y_hat <- predict(model, X)
SSR <- t(y - y_hat) %*% (y - y_hat)
rsq_ridge <- cor(y, y_hat)^2

cat(sprintf("SSR: %5.3f\n R2: %5.3f", SSR, rsq_ridge))

# Lasso Regression - coeficientes vs lambda -------------------------------

res <- glmnet(X, y, alpha = 1, lambda = lambdas_to_try, standardize = FALSE)
plot(res, xvar = "lambda")
